{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79091b5f-294a-45f7-8369-e09fcad37fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon, ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afbe089c-6cf0-49d4-8c14-c6e403a6e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "class ModelComparisonPipeline:\n",
    "    def __init__(self, alpha=0.1):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def format_model_scores(self, classification_reports):\n",
    "        f1s, precisions, recalls = [], [], [],\n",
    "        for report  in classification_reports:\n",
    "            f1s.extend([report['Label 0']['f1-score'], report['Label 1']['f1-score']])\n",
    "            precisions.extend([report['Label 0']['precision'], report['Label 1']['precision']])\n",
    "            recalls.extend([report['Label 0']['recall'], report['Label 1']['recall']])\n",
    "\n",
    "\n",
    "        return {\n",
    "            'f1_score': f1s,\n",
    "            'precision': precisions,\n",
    "            'recall': recalls,\n",
    "        }\n",
    "\n",
    "    def average_scores_across_models(self, model_scores_list):\n",
    "        avg_scores = {}\n",
    "        for key in model_scores_list[0]:\n",
    "            all_values = np.array([model[key] for model in model_scores_list])\n",
    "            avg_scores[key] = list(np.mean(all_values, axis=0))\n",
    "        return avg_scores\n",
    "\n",
    "    def compare_models_on_all_metrics(self, scores_model_a, scores_model_b, model_a_name, model_b_name):\n",
    "        print(f\"\\nComparing '{model_a_name}' vs '{model_b_name}' using Wilcoxon Signed-Rank Test across metrics:\\n\")\n",
    "\n",
    "        for metric in scores_model_a:\n",
    "            try:\n",
    "                print(f\"{'='*150}\")\n",
    "                a_scores = np.array(scores_model_a[metric], dtype=float)\n",
    "                b_scores = np.array(scores_model_b[metric], dtype=float)\n",
    "                if len(a_scores) != len(b_scores):\n",
    "                    print(f\"Skipping metric '{metric}': Unequal lengths.\")\n",
    "                    continue\n",
    "                stat, p_value = wilcoxon(a_scores, b_scores, alternative='greater', method='auto')\n",
    "                print(f\"Metric: {metric}\")\n",
    "                print(f\" - {model_a_name} scores: {a_scores}\")\n",
    "                print(f\" - {model_b_name} scores: {b_scores}\")\n",
    "                print(f\" - Test Statistic: {stat:.4f}\")\n",
    "                print(f\" - p-value: {p_value:.4f}\")\n",
    "                if p_value < self.alpha:\n",
    "                    print(f\"Result: '{model_a_name}' performs significantly better than '{model_b_name}' (p < {self.alpha}) → Reject H₀\")\n",
    "                else:\n",
    "                    print(f\"Result: No significant difference between '{model_a_name}' and '{model_b_name}' (p ≥ {self.alpha}) → Fail to reject H₀\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error with metric '{metric}': {e}\\n\")\n",
    "\n",
    "    def compare_classical_vs_quantum(self, classical_models_results, quantum_models_results, model_a_name, model_b_name):\n",
    "        classical_formatted, quantum_formatted = [], []\n",
    "\n",
    "        for reports in classical_models_results:\n",
    "            classical_formatted.append(self.format_model_scores(reports))\n",
    "        for reports in quantum_models_results:\n",
    "            quantum_formatted.append(self.format_model_scores(reports))\n",
    "\n",
    "        avg_classical = self.average_scores_across_models(classical_formatted)\n",
    "        avg_quantum = self.average_scores_across_models(quantum_formatted)\n",
    "\n",
    "\n",
    "        # Compare metrics statistically\n",
    "        self.compare_models_on_all_metrics(avg_quantum, avg_classical, \"Quantum Models (avg)\", \"Classical Models (avg)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdcdfecb-92a3-4485-90f6-88eb44a9cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IEEE_CIS_AE = {\n",
    "  '0': {'precision': 0.80, 'recall': 0.90, 'f1-score': 0.85, 'support': 569877},\n",
    "  '1': {'precision': 0.58, 'recall': 0.38, 'f1-score': 0.46, 'support': 206630},\n",
    "  'accuracy': 0.76,\n",
    "  'macro avg': {'precision': 0.69, 'recall': 0.64, 'f1-score': 0.65, 'support': 776507},\n",
    "  'weighted avg': {'precision': 0.74, 'recall': 0.76, 'f1-score': 0.74, 'support': 776507}\n",
    "}\n",
    "\n",
    "IEEE_CIS_IF = {\n",
    "  '0': {'precision': 0.80, 'recall': 0.90, 'f1-score': 0.85, 'support': 569877},\n",
    "  '1': {'precision': 0.59, 'recall': 0.40, 'f1-score': 0.48, 'support': 206630},\n",
    "  'accuracy': 0.77,\n",
    "  'macro avg': {'precision': 0.70, 'recall': 0.65, 'f1-score': 0.66, 'support': 776507},\n",
    "  'weighted avg': {'precision': 0.75, 'recall': 0.77, 'f1-score': 0.75, 'support': 776507}\n",
    "}\n",
    "\n",
    "IEEE_CIS_OSVM = {\n",
    "  '0': {'precision': 0.98, 'recall': 0.90, 'f1-score': 0.93, 'support': 569877},\n",
    "  '1': {'precision': 0.13, 'recall': 0.41, 'f1-score': 0.20, 'support': 206630},\n",
    "  'accuracy': 0.77,\n",
    "  'macro avg': {'precision': 0.70, 'recall': 0.65, 'f1-score': 0.66, 'support': 776507},\n",
    "  'weighted avg': {'precision': 0.75, 'recall': 0.77, 'f1-score': 0.75, 'support': 776507}\n",
    "}\n",
    "\n",
    "ISCOM_AE = {\n",
    "  '0': {'precision': 0.65, 'recall': 0.64, 'f1-score': 0.64, 'support': 1463},\n",
    "  '1': {'precision': 0.50, 'recall': 0.51, 'f1-score': 0.50, 'support': 1040},\n",
    "  'accuracy': 0.58,\n",
    "  'macro avg': {'precision': 0.57, 'recall': 0.57, 'f1-score': 0.57, 'support': 2503},\n",
    "  'weighted avg': {'precision': 0.58, 'recall': 0.58, 'f1-score': 0.58, 'support': 2503}\n",
    "}\n",
    "\n",
    "ISCOM_IF = {\n",
    "  '0': {'precision': 0.62, 'recall': 0.80, 'f1-score': 0.70, 'support': 1463},\n",
    "  '1': {'precision': 0.54, 'recall': 0.32, 'f1-score': 0.40, 'support': 1040},\n",
    "  'accuracy': 0.60,\n",
    "  'macro avg': {'precision': 0.58, 'recall': 0.56, 'f1-score': 0.55, 'support': 2503},\n",
    "  'weighted avg': {'precision': 0.59, 'recall': 0.60, 'f1-score': 0.58, 'support': 2503}\n",
    "}\n",
    "\n",
    "ISCOM_OCSVM = {\n",
    "  '0': {'precision': 0.63, 'recall': 0.81, 'f1-score': 0.71, 'support': 1463},\n",
    "  '1': {'precision': 0.56, 'recall': 0.34, 'f1-score': 0.42, 'support': 1040},\n",
    "  'accuracy': 0.61,\n",
    "  'macro avg': {'precision': 0.59, 'recall': 0.57, 'f1-score': 0.57, 'support': 2503},\n",
    "  'weighted avg': {'precision': 0.60, 'recall': 0.61, 'f1-score': 0.59, 'support': 2503}\n",
    "}\n",
    "\n",
    "NSL_KDD_IF = {\n",
    "  '0': {'precision': 0.76, 'recall': 0.91, 'f1-score': 0.82, 'support': 9711},\n",
    "  '1': {'precision': 0.92, 'recall': 0.78, 'f1-score': 0.84, 'support': 12833},\n",
    "  'accuracy': 0.83,\n",
    "  'macro avg': {'precision': 0.84, 'recall': 0.84, 'f1-score': 0.83, 'support': 22544},\n",
    "  'weighted avg': {'precision': 0.85, 'recall': 0.83, 'f1-score': 0.84, 'support': 22544}\n",
    "}\n",
    "\n",
    "NSL_KDD_AE = {\n",
    "  '0': {'precision': 0.65, 'recall': 0.88, 'f1-score': 0.75, 'support': 9711},\n",
    "  '1': {'precision': 0.88, 'recall': 0.64, 'f1-score': 0.74, 'support': 12833},\n",
    "  'accuracy': 0.75,\n",
    "  'macro avg': {'precision': 0.77, 'recall': 0.76, 'f1-score': 0.75, 'support': 22544},\n",
    "  'weighted avg': {'precision': 0.78, 'recall': 0.75, 'f1-score': 0.75, 'support': 22544}\n",
    "}\n",
    "\n",
    "NSL_KDD_OCSVM = {\n",
    "  '0': {'precision': 0.78, 'recall': 0.88, 'f1-score': 0.83, 'support': 9711},\n",
    "  '1': {'precision': 0.90, 'recall': 0.81, 'f1-score': 0.85, 'support': 12833},\n",
    "  'accuracy': 0.84,\n",
    "  'macro avg': {'precision': 0.84, 'recall': 0.85, 'f1-score': 0.84, 'support': 22544},\n",
    "  'weighted avg': {'precision': 0.85, 'recall': 0.84, 'f1-score': 0.84, 'support': 22544}\n",
    "}\n",
    "\n",
    "\n",
    "classical_models_results = [\n",
    "    # IEEE_CIS classical models\n",
    "    [\n",
    "        {'Label 0': IEEE_CIS_AE['0'], 'Label 1': IEEE_CIS_AE['1']},\n",
    "        {'Label 0': IEEE_CIS_IF['0'], 'Label 1': IEEE_CIS_IF['1']},\n",
    "        {'Label 0': IEEE_CIS_OSVM['0'], 'Label 1': IEEE_CIS_OSVM['1']},\n",
    "    ],\n",
    "    # ISCOM classical models\n",
    "    [\n",
    "        {'Label 0': ISCOM_AE['0'], 'Label 1': ISCOM_AE['1']},\n",
    "        {'Label 0': ISCOM_IF['0'], 'Label 1': ISCOM_IF['1']},\n",
    "        {'Label 0': ISCOM_OCSVM['0'], 'Label 1': ISCOM_OCSVM['1']},\n",
    "    ],\n",
    "    # NSL-KDD classical models\n",
    "    [\n",
    "        {'Label 0': NSL_KDD_AE['0'], 'Label 1': NSL_KDD_AE['1']},\n",
    "        {'Label 0': NSL_KDD_IF['0'], 'Label 1': NSL_KDD_IF['1']},\n",
    "        {'Label 0': NSL_KDD_OCSVM['0'], 'Label 1': NSL_KDD_OCSVM['1']},\n",
    "    ]\n",
    "]\n",
    "\n",
    "ocsvm_scores = {\n",
    "    'f1_score': [0.71,0.42, 0.93,0.20, 0.75,0.74],\n",
    "    'precision': [0.63,0.56, 0.98,0.13, 0.65,0.88],\n",
    "    'recall' : [0.81,0.34, 0.90,0.41, 0.88,0.64]\n",
    "}\n",
    "\n",
    "isolation_forest_scores = {\n",
    "\n",
    "    'f1_score':     [0.70,0.40, 0.85,0.48, 0.83,0.85],\n",
    "    'precision':   [0.62,0.54, 0.80,0.59, 0.78,0.90],\n",
    "    'recall':      [0.80,0.32, 0.90,0.40, 0.88,0.81]\n",
    "}\n",
    "\n",
    "autoencoder_scores = {\n",
    "    'f1_score':     [0.64,0.50, 0.85,0.46, 0.75,0.74],\n",
    "    'precision':   [0.65,0.50, 0.80,0.58, 0.,65,0.88],\n",
    "    'recall':      [0.64,0.51, 0.90,0.38, 0.88,0.64]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bc5594b-1ebe-46f0-a29a-a339e18f8ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IEEE_CIS_QSVM = {\n",
    "  'Label 0': {'precision': 0.97, 'recall': 0.96, 'f1-score': 0.965, 'support': 900.0},\n",
    "  'Label 1': {'precision': 0.85, 'recall': 0.88, 'f1-score': 0.865, 'support': 100.0},\n",
    "  'accuracy': 0.95,\n",
    "  'macro avg': {'precision': 0.91, 'recall': 0.92, 'f1-score': 0.915, 'support': 1000.0},\n",
    "  'weighted avg': {'precision': 0.95, 'recall': 0.95, 'f1-score': 0.95, 'support': 1000.0}\n",
    "}\n",
    "\n",
    "IEEE_CIS_QNN = {\n",
    "  'Label 0': {'precision': 0.98, 'recall': 0.96, 'f1-score': 0.97, 'support': 900.0},\n",
    "  'Label 1': {'precision': 0.86, 'recall': 0.92, 'f1-score': 0.89, 'support': 100.0},\n",
    "  'accuracy': 0.9649,\n",
    "  'macro avg': {'precision': 0.92, 'recall': 0.94, 'f1-score': 0.93, 'support': 1000.0},\n",
    "  'weighted avg': {'precision': 0.96, 'recall': 0.96, 'f1-score': 0.96, 'support': 1000.0}\n",
    "}\n",
    "\n",
    "IEEE_CIS_QAE = {\n",
    "  'Label 0': {'precision': 0.87, 'recall': 0.83, 'f1-score': 0.85, 'support': 900.0},\n",
    "  'Label 1': {'precision': 0.45, 'recall': 0.58, 'f1-score': 0.51, 'support': 100.0},\n",
    "  'accuracy': 0.835,\n",
    "  'macro avg': {'precision': 0.66, 'recall': 0.71, 'f1-score': 0.68, 'support': 1000.0},\n",
    "  'weighted avg': {'precision': 0.81, 'recall': 0.835, 'f1-score': 0.82, 'support': 1000.0}\n",
    "}\n",
    "\n",
    "SECOM_QSVM = {\n",
    "  'Label 0': {'precision': 0.95, 'recall': 0.94, 'f1-score': 0.945, 'support': 1557.0},\n",
    "  'Label 1': {'precision': 0.75, 'recall': 0.8, 'f1-score': 0.77, 'support': 98.0},\n",
    "  'accuracy': 0.84,\n",
    "  'macro avg': {'precision': 0.85, 'recall': 0.87, 'f1-score': 0.86, 'support': 1655.0},\n",
    "  'weighted avg': {'precision': 0.93, 'recall': 0.94, 'f1-score': 0.93, 'support': 1655.0}\n",
    "}\n",
    "\n",
    "SECOM_QNN = {\n",
    "  'Label 0': {'precision': 0.96, 'recall': 0.94, 'f1-score': 0.95, 'support': 1557.0},\n",
    "  'Label 1': {'precision': 0.82, 'recall': 0.87, 'f1-score': 0.84, 'support': 98.0},\n",
    "  'accuracy': 0.9351,\n",
    "  'macro avg': {'precision': 0.89, 'recall': 0.905, 'f1-score': 0.895, 'support': 1655.0},\n",
    "  'weighted avg': {'precision': 0.93, 'recall': 0.935, 'f1-score': 0.934, 'support': 1655.0}\n",
    "}\n",
    "\n",
    "SECOM_QAE = {\n",
    "  'Label 0': {'precision': 0.85, 'recall': 0.81, 'f1-score': 0.83, 'support': 1557.0},\n",
    "  'Label 1': {'precision': 0.55, 'recall': 0.7, 'f1-score': 0.62, 'support': 98.0},\n",
    "  'accuracy': 0.82,\n",
    "  'macro avg': {'precision': 0.7, 'recall': 0.755, 'f1-score': 0.725, 'support': 1655.0},\n",
    "  'weighted avg': {'precision': 0.81, 'recall': 0.82, 'f1-score': 0.815, 'support': 1655.0}\n",
    "}\n",
    "\n",
    "NSL_KDD_QSVM = {\n",
    "  'Label 0': {'precision': 0.87, 'recall': 0.85, 'f1-score': 0.86, 'support': 743.0},\n",
    "  'Label 1': {'precision': 0.84, 'recall': 0.86, 'f1-score': 0.85, 'support': 1250.0},\n",
    "  'accuracy': 0.85,\n",
    "  'macro avg': {'precision': 0.855, 'recall': 0.855, 'f1-score': 0.855, 'support': 1993.0},\n",
    "  'weighted avg': {'precision': 0.85, 'recall': 0.85, 'f1-score': 0.85, 'support': 1993.0}\n",
    "}\n",
    "\n",
    "NSL_KDD_QNN = {\n",
    "  'Label 0': {'precision': 0.78, 'recall': 0.73, 'f1-score': 0.755, 'support': 743.0},\n",
    "  'Label 1': {'precision': 0.7, 'recall': 0.75, 'f1-score': 0.725, 'support': 1250.0},\n",
    "  'accuracy': 0.7427,\n",
    "  'macro avg': {'precision': 0.74, 'recall': 0.74, 'f1-score': 0.74, 'support': 1993.0},\n",
    "  'weighted avg': {'precision': 0.745, 'recall': 0.743, 'f1-score': 0.744, 'support': 1993.0}\n",
    "}\n",
    "\n",
    "NSL_KDD_QAE = {\n",
    "  'Label 0': {'precision': 0.82, 'recall': 0.78, 'f1-score': 0.8, 'support': 743.0},\n",
    "  'Label 1': {'precision': 0.76, 'recall': 0.8, 'f1-score': 0.78, 'support': 1250.0},\n",
    "  'accuracy': 0.8,\n",
    "  'macro avg': {'precision': 0.79, 'recall': 0.79, 'f1-score': 0.79, 'support': 1993.0},\n",
    "  'weighted avg': {'precision': 0.8, 'recall': 0.8, 'f1-score': 0.8, 'support': 1993.0}\n",
    "}\n",
    "\n",
    "\n",
    "quantum_models_results = [\n",
    "    # IEEE_CIS classical models\n",
    "    [\n",
    "        {'Label 0': IEEE_CIS_QAE['Label 0'], 'Label 1': IEEE_CIS_QAE['Label 1']},\n",
    "        {'Label 0': IEEE_CIS_QNN['Label 0'], 'Label 1': IEEE_CIS_QNN['Label 1']},\n",
    "        {'Label 0': IEEE_CIS_QSVM['Label 0'], 'Label 1': IEEE_CIS_QSVM['Label 1']},\n",
    "    ],\n",
    "    # ISCOM classical models\n",
    "    [\n",
    "        {'Label 0': SECOM_QAE['Label 0'], 'Label 1': SECOM_QAE['Label 1']},\n",
    "        {'Label 0': SECOM_QNN['Label 0'], 'Label 1': SECOM_QNN['Label 1']},\n",
    "        {'Label 0': SECOM_QSVM['Label 0'], 'Label 1': SECOM_QSVM['Label 1']},\n",
    "    ],\n",
    "    # NSL-KDD classical models\n",
    "    [\n",
    "        {'Label 0': NSL_KDD_QAE['Label 0'], 'Label 1': NSL_KDD_QAE['Label 1']},\n",
    "        {'Label 0': NSL_KDD_QNN['Label 0'], 'Label 1': NSL_KDD_QNN['Label 1']},\n",
    "        {'Label 0': NSL_KDD_QSVM['Label 0'], 'Label 1': NSL_KDD_QSVM['Label 1']},\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "QNN_scores = {\n",
    "    'f1_score': [0.95,0.84, 0.97,0.89, 0.755,0.725],\n",
    "    'precision': [0.96,0.82, 0.98,0.86, 0.78,0.7],\n",
    "    'recall': [0.94,0.87, 0.96,0.92, 0.73,0.75]\n",
    "}\n",
    "\n",
    "QAE_scores = {\n",
    "    'f1_score': [0.755,0.725, 0.83,0.51, 0.85,0.51],\n",
    "    'precision': [0.78,0.7, 0.87,0.45, 0.87,0.45],\n",
    "    'recall': [0.73,0.75, 0.83,0.58, 0.83,0.58]\n",
    "}\n",
    "\n",
    "QSVM_scores = {\n",
    "    'f1_score': [0.945,0.77, 0.965,0.865, 0.86,0.85],\n",
    "    'precision': [0.95,0.75, 0.97,0.85, 0.87,0.84],\n",
    "    'recall': [0.94,0.8, 0.96,0.88, 0.85,0.86]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b04be0c5-d3f2-4784-8ced-e5127db5b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = ModelComparisonPipeline(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f6bb2c9-c72b-4d7f-a934-225bc03fde51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'Isolation Forest' vs 'OCSVM' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - Isolation Forest scores: [0.7  0.4  0.85 0.48 0.83 0.85]\n",
      " - OCSVM scores: [0.71 0.42 0.93 0.2  0.75 0.74]\n",
      " - Test Statistic: 14.0000\n",
      " - p-value: 0.2812\n",
      "Result: No significant difference between 'Isolation Forest' and 'OCSVM' (p ≥ 0.1) → Fail to reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: precision\n",
      " - Isolation Forest scores: [0.62 0.54 0.8  0.59 0.78 0.9 ]\n",
      " - OCSVM scores: [0.63 0.56 0.98 0.13 0.65 0.88]\n",
      " - Test Statistic: 12.5000\n",
      " - p-value: 0.4219\n",
      "Result: No significant difference between 'Isolation Forest' and 'OCSVM' (p ≥ 0.1) → Fail to reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - Isolation Forest scores: [0.8  0.32 0.9  0.4  0.88 0.81]\n",
      " - OCSVM scores: [0.81 0.34 0.9  0.41 0.88 0.64]\n",
      " - Test Statistic: 4.0000\n",
      " - p-value: 0.6425\n",
      "Result: No significant difference between 'Isolation Forest' and 'OCSVM' (p ≥ 0.1) → Fail to reject H₀\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Reyan\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_wilcoxon.py:199: UserWarning: Sample size too small for normal approximation.\n",
      "  temp = _wilcoxon_iv(x, y, zero_method, correction, alternative, method, axis)\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(isolation_forest_scores,ocsvm_scores,\"Isolation Forest\", \"OCSVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "549ae0b4-4a22-46bb-865e-743e1d3b11ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'QNN' vs 'OCSVM' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - QNN scores: [0.95  0.84  0.97  0.89  0.755 0.725]\n",
      " - OCSVM scores: [0.71 0.42 0.93 0.2  0.75 0.74]\n",
      " - Test Statistic: 19.0000\n",
      " - p-value: 0.0469\n",
      "Result: 'QNN' performs significantly better than 'OCSVM' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: precision\n",
      " - QNN scores: [0.96 0.82 0.98 0.86 0.78 0.7 ]\n",
      " - OCSVM scores: [0.63 0.56 0.98 0.13 0.65 0.88]\n",
      " - Test Statistic: 13.0000\n",
      " - p-value: 0.0690\n",
      "Result: 'QNN' performs significantly better than 'OCSVM' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - QNN scores: [0.94 0.87 0.96 0.92 0.73 0.75]\n",
      " - OCSVM scores: [0.81 0.34 0.9  0.41 0.88 0.64]\n",
      " - Test Statistic: 17.0000\n",
      " - p-value: 0.1094\n",
      "Result: No significant difference between 'QNN' and 'OCSVM' (p ≥ 0.1) → Fail to reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(QNN_scores,ocsvm_scores,\"QNN\", \"OCSVM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2398f398-f46a-48dd-ac1a-4ec7c18d3669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'QNN' vs 'QAE' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - QNN scores: [0.95  0.84  0.97  0.89  0.755 0.725]\n",
      " - QAE scores: [0.755 0.725 0.83  0.51  0.85  0.51 ]\n",
      " - Test Statistic: 20.0000\n",
      " - p-value: 0.0312\n",
      "Result: 'QNN' performs significantly better than 'QAE' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: precision\n",
      " - QNN scores: [0.96 0.82 0.98 0.86 0.78 0.7 ]\n",
      " - QAE scores: [0.78 0.7  0.87 0.45 0.87 0.45]\n",
      " - Test Statistic: 20.0000\n",
      " - p-value: 0.0312\n",
      "Result: 'QNN' performs significantly better than 'QAE' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - QNN scores: [0.94 0.87 0.96 0.92 0.73 0.75]\n",
      " - QAE scores: [0.73 0.75 0.83 0.58 0.83 0.58]\n",
      " - Test Statistic: 20.0000\n",
      " - p-value: 0.0312\n",
      "Result: 'QNN' performs significantly better than 'QAE' (p < 0.1) → Reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(QNN_scores,QAE_scores,\"QNN\", \"QAE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ade9067-341c-47a4-add6-5516e1de0636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'QNN' vs 'Isolation Forest' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - QNN scores: [0.95  0.84  0.97  0.89  0.755 0.725]\n",
      " - Isolation Forest scores: [0.7  0.4  0.85 0.48 0.83 0.85]\n",
      " - Test Statistic: 17.0000\n",
      " - p-value: 0.1094\n",
      "Result: No significant difference between 'QNN' and 'Isolation Forest' (p ≥ 0.1) → Fail to reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: precision\n",
      " - QNN scores: [0.96 0.82 0.98 0.86 0.78 0.7 ]\n",
      " - Isolation Forest scores: [0.62 0.54 0.8  0.59 0.78 0.9 ]\n",
      " - Test Statistic: 13.0000\n",
      " - p-value: 0.0690\n",
      "Result: 'QNN' performs significantly better than 'Isolation Forest' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - QNN scores: [0.94 0.87 0.96 0.92 0.73 0.75]\n",
      " - Isolation Forest scores: [0.8  0.32 0.9  0.4  0.88 0.81]\n",
      " - Test Statistic: 15.0000\n",
      " - p-value: 0.2188\n",
      "Result: No significant difference between 'QNN' and 'Isolation Forest' (p ≥ 0.1) → Fail to reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(QNN_scores,isolation_forest_scores,\"QNN\", \"Isolation Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "215ff9ff-499e-4127-98a5-f00089062193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'QNN' vs 'QSVM' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - QNN scores: [0.95  0.84  0.97  0.89  0.755 0.725]\n",
      " - QSVM scores: [0.945 0.77  0.965 0.865 0.86  0.85 ]\n",
      " - Test Statistic: 10.0000\n",
      " - p-value: 0.5781\n",
      "Result: No significant difference between 'QNN' and 'QSVM' (p ≥ 0.1) → Fail to reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: precision\n",
      " - QNN scores: [0.96 0.82 0.98 0.86 0.78 0.7 ]\n",
      " - QSVM scores: [0.95 0.75 0.97 0.85 0.87 0.84]\n",
      " - Test Statistic: 10.0000\n",
      " - p-value: 0.5781\n",
      "Result: No significant difference between 'QNN' and 'QSVM' (p ≥ 0.1) → Fail to reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - QNN scores: [0.94 0.87 0.96 0.92 0.73 0.75]\n",
      " - QSVM scores: [0.94 0.8  0.96 0.88 0.85 0.86]\n",
      " - Test Statistic: 3.0000\n",
      " - p-value: 0.7674\n",
      "Result: No significant difference between 'QNN' and 'QSVM' (p ≥ 0.1) → Fail to reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(QNN_scores,QSVM_scores,\"QNN\", \"QSVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37482c3d-7c95-4edc-9e72-4bae52af0271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'QNN' vs 'AE' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - QNN scores: [0.95  0.84  0.97  0.89  0.755 0.725]\n",
      " - AE scores: [0.64 0.5  0.85 0.46 0.75 0.74]\n",
      " - Test Statistic: 19.0000\n",
      " - p-value: 0.0469\n",
      "Result: 'QNN' performs significantly better than 'AE' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Skipping metric 'precision': Unequal lengths.\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - QNN scores: [0.94 0.87 0.96 0.92 0.73 0.75]\n",
      " - AE scores: [0.64 0.51 0.9  0.38 0.88 0.64]\n",
      " - Test Statistic: 18.0000\n",
      " - p-value: 0.0781\n",
      "Result: 'QNN' performs significantly better than 'AE' (p < 0.1) → Reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(QNN_scores,autoencoder_scores,\"QNN\", \"AE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b53efb6b-59d5-41c0-a08a-4f147f00f1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'QSVM' vs 'Isolation Forest' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - QSVM scores: [0.945 0.77  0.965 0.865 0.86  0.85 ]\n",
      " - Isolation Forest scores: [0.7  0.4  0.85 0.48 0.83 0.85]\n",
      " - Test Statistic: 15.0000\n",
      " - p-value: 0.0216\n",
      "Result: 'QSVM' performs significantly better than 'Isolation Forest' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: precision\n",
      " - QSVM scores: [0.95 0.75 0.97 0.85 0.87 0.84]\n",
      " - Isolation Forest scores: [0.62 0.54 0.8  0.59 0.78 0.9 ]\n",
      " - Test Statistic: 20.0000\n",
      " - p-value: 0.0312\n",
      "Result: 'QSVM' performs significantly better than 'Isolation Forest' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - QSVM scores: [0.94 0.8  0.96 0.88 0.85 0.86]\n",
      " - Isolation Forest scores: [0.8  0.32 0.9  0.4  0.88 0.81]\n",
      " - Test Statistic: 20.0000\n",
      " - p-value: 0.0312\n",
      "Result: 'QSVM' performs significantly better than 'Isolation Forest' (p < 0.1) → Reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(QSVM_scores,isolation_forest_scores,\"QSVM\", \"Isolation Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "571e228b-9d04-422f-b322-bc3df62e8ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'QSVM' vs 'AE' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - QSVM scores: [0.945 0.77  0.965 0.865 0.86  0.85 ]\n",
      " - AE scores: [0.64 0.5  0.85 0.46 0.75 0.74]\n",
      " - Test Statistic: 21.0000\n",
      " - p-value: 0.0156\n",
      "Result: 'QSVM' performs significantly better than 'AE' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Skipping metric 'precision': Unequal lengths.\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - QSVM scores: [0.94 0.8  0.96 0.88 0.85 0.86]\n",
      " - AE scores: [0.64 0.51 0.9  0.38 0.88 0.64]\n",
      " - Test Statistic: 20.0000\n",
      " - p-value: 0.0312\n",
      "Result: 'QSVM' performs significantly better than 'AE' (p < 0.1) → Reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(QSVM_scores,autoencoder_scores,\"QSVM\", \"AE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b769487-3d46-444d-be36-8d9c8031d6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'QSVM' vs 'QAE' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - QSVM scores: [0.945 0.77  0.965 0.865 0.86  0.85 ]\n",
      " - QAE scores: [0.755 0.725 0.83  0.51  0.85  0.51 ]\n",
      " - Test Statistic: 21.0000\n",
      " - p-value: 0.0156\n",
      "Result: 'QSVM' performs significantly better than 'QAE' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: precision\n",
      " - QSVM scores: [0.95 0.75 0.97 0.85 0.87 0.84]\n",
      " - QAE scores: [0.78 0.7  0.87 0.45 0.87 0.45]\n",
      " - Test Statistic: 15.0000\n",
      " - p-value: 0.0216\n",
      "Result: 'QSVM' performs significantly better than 'QAE' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - QSVM scores: [0.94 0.8  0.96 0.88 0.85 0.86]\n",
      " - QAE scores: [0.73 0.75 0.83 0.58 0.83 0.58]\n",
      " - Test Statistic: 21.0000\n",
      " - p-value: 0.0156\n",
      "Result: 'QSVM' performs significantly better than 'QAE' (p < 0.1) → Reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(QSVM_scores,QAE_scores,\"QSVM\", \"QAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f47c79a2-79e2-4878-a5ce-1346c66b0cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'QSVM' vs 'OCSVM' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - QSVM scores: [0.945 0.77  0.965 0.865 0.86  0.85 ]\n",
      " - OCSVM scores: [0.71 0.42 0.93 0.2  0.75 0.74]\n",
      " - Test Statistic: 21.0000\n",
      " - p-value: 0.0156\n",
      "Result: 'QSVM' performs significantly better than 'OCSVM' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: precision\n",
      " - QSVM scores: [0.95 0.75 0.97 0.85 0.87 0.84]\n",
      " - OCSVM scores: [0.63 0.56 0.98 0.13 0.65 0.88]\n",
      " - Test Statistic: 18.0000\n",
      " - p-value: 0.0781\n",
      "Result: 'QSVM' performs significantly better than 'OCSVM' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - QSVM scores: [0.94 0.8  0.96 0.88 0.85 0.86]\n",
      " - OCSVM scores: [0.81 0.34 0.9  0.41 0.88 0.64]\n",
      " - Test Statistic: 20.0000\n",
      " - p-value: 0.0312\n",
      "Result: 'QSVM' performs significantly better than 'OCSVM' (p < 0.1) → Reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(QSVM_scores,ocsvm_scores,\"QSVM\", \"OCSVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2c35d02-5d8b-4a5d-85ba-721a59d98168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'QSVM' vs 'QNN' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - QSVM scores: [0.945 0.77  0.965 0.865 0.86  0.85 ]\n",
      " - QNN scores: [0.95  0.84  0.97  0.89  0.755 0.725]\n",
      " - Test Statistic: 11.0000\n",
      " - p-value: 0.5000\n",
      "Result: No significant difference between 'QSVM' and 'QNN' (p ≥ 0.1) → Fail to reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: precision\n",
      " - QSVM scores: [0.95 0.75 0.97 0.85 0.87 0.84]\n",
      " - QNN scores: [0.96 0.82 0.98 0.86 0.78 0.7 ]\n",
      " - Test Statistic: 11.0000\n",
      " - p-value: 0.5000\n",
      "Result: No significant difference between 'QSVM' and 'QNN' (p ≥ 0.1) → Fail to reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - QSVM scores: [0.94 0.8  0.96 0.88 0.85 0.86]\n",
      " - QNN scores: [0.94 0.87 0.96 0.92 0.73 0.75]\n",
      " - Test Statistic: 7.0000\n",
      " - p-value: 0.2326\n",
      "Result: No significant difference between 'QSVM' and 'QNN' (p ≥ 0.1) → Fail to reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(QSVM_scores,QNN_scores,\"QSVM\", \"QNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "892815b0-aa47-4c3d-bef8-d787522ded0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'QAE' vs 'AE' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - QAE scores: [0.755 0.725 0.83  0.51  0.85  0.51 ]\n",
      " - AE scores: [0.64 0.5  0.85 0.46 0.75 0.74]\n",
      " - Test Statistic: 14.0000\n",
      " - p-value: 0.2812\n",
      "Result: No significant difference between 'QAE' and 'AE' (p ≥ 0.1) → Fail to reject H₀\n",
      "======================================================================================================================================================\n",
      "Skipping metric 'precision': Unequal lengths.\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - QAE scores: [0.73 0.75 0.83 0.58 0.83 0.58]\n",
      " - AE scores: [0.64 0.51 0.9  0.38 0.88 0.64]\n",
      " - Test Statistic: 15.0000\n",
      " - p-value: 0.2188\n",
      "Result: No significant difference between 'QAE' and 'AE' (p ≥ 0.1) → Fail to reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(QAE_scores,autoencoder_scores,\"QAE\", \"AE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58ce40f1-7e27-4577-8424-ed593956cf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'QAE' vs 'Isolation Forest' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - QAE scores: [0.755 0.725 0.83  0.51  0.85  0.51 ]\n",
      " - Isolation Forest scores: [0.7  0.4  0.85 0.48 0.83 0.85]\n",
      " - Test Statistic: 13.5000\n",
      " - p-value: 0.3438\n",
      "Result: No significant difference between 'QAE' and 'Isolation Forest' (p ≥ 0.1) → Fail to reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: precision\n",
      " - QAE scores: [0.78 0.7  0.87 0.45 0.87 0.45]\n",
      " - Isolation Forest scores: [0.62 0.54 0.8  0.59 0.78 0.9 ]\n",
      " - Test Statistic: 12.0000\n",
      " - p-value: 0.4219\n",
      "Result: No significant difference between 'QAE' and 'Isolation Forest' (p ≥ 0.1) → Fail to reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - QAE scores: [0.73 0.75 0.83 0.58 0.83 0.58]\n",
      " - Isolation Forest scores: [0.8  0.32 0.9  0.4  0.88 0.81]\n",
      " - Test Statistic: 10.0000\n",
      " - p-value: 0.5781\n",
      "Result: No significant difference between 'QAE' and 'Isolation Forest' (p ≥ 0.1) → Fail to reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_models_on_all_metrics(QAE_scores,isolation_forest_scores,\"QAE\", \"Isolation Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36d62b9f-524b-4a59-b579-70f913d7b139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing 'Quantum Models (avg)' vs 'Classical Models (avg)' using Wilcoxon Signed-Rank Test across metrics:\n",
      "\n",
      "======================================================================================================================================================\n",
      "Metric: f1_score\n",
      " - Quantum Models (avg) scores: [0.82666667 0.63666667 0.89166667 0.81833333 0.92333333 0.82833333]\n",
      " - Classical Models (avg) scores: [0.74666667 0.56666667 0.79       0.57333333 0.82333333 0.49      ]\n",
      " - Test Statistic: 21.0000\n",
      " - p-value: 0.0156\n",
      "Result: 'Quantum Models (avg)' performs significantly better than 'Classical Models (avg)' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: precision\n",
      " - Quantum Models (avg) scores: [0.84666667 0.58666667 0.90666667 0.79333333 0.93       0.81333333]\n",
      " - Classical Models (avg) scores: [0.7        0.65333333 0.72666667 0.68333333 0.79666667 0.53      ]\n",
      " - Test Statistic: 20.0000\n",
      " - p-value: 0.0312\n",
      "Result: 'Quantum Models (avg)' performs significantly better than 'Classical Models (avg)' (p < 0.1) → Reject H₀\n",
      "======================================================================================================================================================\n",
      "Metric: recall\n",
      " - Quantum Models (avg) scores: [0.80666667 0.69333333 0.87666667 0.84666667 0.91666667 0.84666667]\n",
      " - Classical Models (avg) scores: [0.80666667 0.51       0.87       0.5        0.86333333 0.52      ]\n",
      " - Test Statistic: 15.0000\n",
      " - p-value: 0.0216\n",
      "Result: 'Quantum Models (avg)' performs significantly better than 'Classical Models (avg)' (p < 0.1) → Reject H₀\n"
     ]
    }
   ],
   "source": [
    "pipeline.compare_classical_vs_quantum(classical_models_results, quantum_models_results, \"Classical\", \"Quantum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f4d2f8-a623-4105-9171-008b5eddacec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
