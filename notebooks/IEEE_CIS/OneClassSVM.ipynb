{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score,precision_score,accuracy_score,classification_report,roc_auc_score,confusion_matrix,roc_curve,auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import optuna\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 569877, Anomalous: 20663\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "df_normal = df[df['label'] == 0]\n",
    "df_anomalous = df[df['label'] == 1]\n",
    "df_normal = df_normal.drop(columns=['label'])\n",
    "df_anomalous = df_anomalous.drop(columns=['label'])\n",
    "# Data Distribution\n",
    "print(f\"Normal: {len(df_normal)}, Anomalous: {len(df_anomalous)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "- **K-fold cross-validation** was used to ensure the model was trained on different subsets of the data. Since only a subset of the normal class was used for testing, relying on a single split might not provide the most reliable results. K-fold cross-validation helps mitigate this issue by training the model across multiple data folds, leading to a more robust evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KFold object with 10 splits\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "# Iterate through the folds\n",
    "for train_index, test_index in kf.split(df_normal):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test = df_normal.iloc[train_index], df_normal.iloc[test_index]\n",
    "    y_test = np.full(len(X_test), 0)\n",
    "    # add anomalous data to the test set\n",
    "    X_test = pd.concat([X_test, df_anomalous])\n",
    "    y_test = np.concatenate([y_test, np.full(len(df_anomalous), 1)])\n",
    "    \n",
    "    # Train the One Class SVM model\n",
    "    model = OneClassSVM(kernel='rbf', gamma='scale', nu=0.1)\n",
    "    model.fit(X_train)\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [1 if x == -1 else 0 for x in y_pred]\n",
    "    \n",
    "    # Calculate the F1 score\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Append the results to the list\n",
    "    results.append({\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'accuracy': accuracy\n",
    "    })\n",
    "    \n",
    "print(f\"F1 Score: {np.mean([result['f1'] for result in results])}\")\n",
    "print(f\"Precision: {np.mean([result['precision'] for result in results])}\")\n",
    "print(f\"Accuracy: {np.mean([result['accuracy'] for result in results])}\")\n",
    "print(f\"Classification Report: {classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OneClass SVM models are not working well for higer dimensional data. Its taking lot of time nearly 3-4 hours to train them and they are just giving comparable or worse results than the Isolation Forest and AutoEncoder models. Which are just taking at max few minutes to train. So the study on OneClass SVM is not done thoroughly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bytive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
